<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resources â€” Wisconsin Neuromorphic Computing and NeuroAI Lab</title>
    <link rel="icon" href="static/website_icon.jpg" type="image/jpeg">
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div id="header-placeholder"></div>

    <section id="resources-hero" class="resources-hero fade-in">
        <h1>Resources</h1>
    </section>

    <section id="resources" class="fade-in">
        <div class="resources-container">
            <div class="resource-category">
                <h2>Learn More about Neuromorphic Computing</h2>
                <ul>
                    <li><a href="https://www.nature.com/articles/s43588-021-00184-y">Opportunities for neuromorphic
                            computing algorithms and applications</a></li>
                    <li><a href="https://open-neuromorphic.org/">Neuromorphic Computing and Engineering Community</a>
                    </li>
                    <li><a href="https://ncg.ucsc.edu/resources/">Brain-Inspired Systems at UC Santa Cruz</a></li>
                    <li><a href="https://www.youtube.com/watch?v=2XX8KLMyQN4">Neuromorphic computing from theory to
                            applications</a></li>
                </ul>
            </div>

            <div class="resource-category">
                <h2>If you are new to neuromorphic computing</h2>
                <ul>
                    <li><a href="https://browse.arxiv.org/abs/2109.12894">SNNs using backprop. This is SNNs 101</a></li>
                    <li><a href="https://snntorch.readthedocs.io/en/latest/">snnTorch tutorials</a></li>
                    <li><a href="https://github.com/open-neuromorphic/awesome-neuromorphic-hw">Repo for new papers in
                            the neuromorphic hardware domain</a></li>
                </ul>
            </div>

            <div class="resource-category">
                <h2>Organizations in Neuromorphic Computing</h2>
                <ul>
                    <li><a href="https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html">Intel</a>
                    </li>
                    <li><a href="https://www.epfl.ch/research/domains/bluebrain/">Blue Brain Project</a></li>
                    <li><a href="https://ncg.ucsc.edu/">UC Santa Cruz</a></li>
                    <li><a href="https://sites.psu.edu/sengupta/">Penn State</a></li>
                    <li><a href="https://intelligentcomputinglab.yale.edu/">Yale University</a></li>
                    <li><a
                            href="https://www.humanbrainproject.eu/en/science-development/focus-areas/neuromorphic-computing/">Human
                            Brain Project</a></li>
                    <li><a
                            href="https://www.ebrains.eu/modelling-simulation-and-computing/computing/neuromorphic-computing/">EBRAINS</a>
                    </li>
                </ul>
            </div>

            <div class="resource-category">
                <h2>Digital Hardware Enthusiasts</h2>
                <ul>
                    <li><a href="https://github.com/minnellf/NN2FPGA-open">Design and Optimization of Residual Neural
                            Network Accelerators for Low-Power FPGAs</a></li>
                    <li><a href="#">FireFly: A High-Throughput Hardware Accelerator for Spiking Neural Networks with
                            Efficient DSP and Memory Optimization</a></li>
                    <li><a href="#">DeltaRNN: A Power-efficient Recurrent Neural Network Accelerator</a></li>
                    <li><a href="#">Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting Spatio-Temporal
                            Sparsity</a></li>
                </ul>
            </div>

            <div class="resource-category">
                <h2>General Know-How of DNN Accelerators Design</h2>
                <ul>
                    <li><a href="#">Efficient Processing of Deep Neural Networks, Vivienne Sze et al.</a></li>
                    <li><a href="#">Efficient Processing of Deep Neural Networks: A Tutorial and Survey, Vivienne Sze et
                            al.</a></li>
                    <li><a href="#">Full Stack Optimization of Transformer Inference: a Survey, Sehoon Kim et al.</a>
                    </li>
                </ul>
            </div>
        </div>
    </section>
<div id="footer-placeholder"></div>

    <script src="static/script.js"></script>
</body>

</html>